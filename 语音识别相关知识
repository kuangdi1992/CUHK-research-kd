 语音识别的相关知识：　　
 相关地址：https://juejin.im/entry/58e9aaa2a0bb9f00691fed31
    一个语音对话系统一般包含四个主要组成部分中的一个或多个：语音识别系统将语音转化为文本、语义理解
 系统提取用户说话的语义信息、文字转语音系统将内容转化为语音、对话管理系统连接其他三个系统并完成
 与实际应用场景的沟通。
    语音识别系统主要由４部分组成：信号处理和特征提取、声学模型(AM)、语言模型(LM)和解码搜索部分。（
图没办法贴）
    信号处理和特征提取是语音识别系统的第一部分，接受最原始的音频信号，通过消除噪声和信道失真对语音进
行增强，将信号从时域转化到频域，并为后面的声学模型提取合适的有代表性的特征向量。
    声学模型以特征提取部分生成的特征为输入，为可变长特征序列生成声学模型分数。
    语言模型估计通过训练语料学习词与词之间的相互关系，来估计假设词序列的可能性，又叫语言模型分数。
如果了解领域或任务相关的先验知识，语言模型的分数通常可以估计的更准确。
    解码搜索综合声学模型分数与语言模型分数的结果，将总体输出分数最高的词序列当做识别结果。
    语音识别就是一个先编码后解码的过程，信号处理和特征提取就是编码的过程，由原始的语音得到语音向
量。后面即是对语音向量的解码，而解码需要的Acoustic Model、Language Model就是上面提到过的声学
模型和语言模型。
    在过去，信号处理和特征抽取一般用梅尔倒谱系数或者相对频谱变换-感知线性预测 作为特征向量，然后
使用混合高斯模型-隐马尔可夫模型（GMM-HMM）作为声学模型，然后再用最大似然准则（maximum likelihood，ML）
去训练，再之后序列鉴别性训练算法，比如最小分类错误（MCE）和最小音素错误（MPE）等准则被提了出来。
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
　　　　　　　　　　　　　　　　ＣＴＣ方法（语音识别相关）
https://www.zhihu.com/question/47642307
  传统的语音识别系统，是由语音模型、词典、语言模型构成的，而其中的语音模型和语言模型是分别训练的。
这就造成每一部分的训练目标（语音模型的likelihood，语言模型的perplexity）都与整个系统的训练目
标（word error rate）不一致。
  而使用了CTC之后，从语音特征（输入端）到文字串（输出端）就只有一个神经网络模型（这就叫“端到端”模型），
可以直接用WER的某种proxy作为目标函数来训练这个神经网络，避免花费无用功去优化一个别的目标函数。
  当然，实际中因为可以获取的文本数据比语音数据多得多，所以往往还会用文本数据训练一个更好的语言模型，与CTC神
经网络结合使用。（所以我在实验中仍然需要使用ＣＴＣ方法，这样就可以直接使用ＷＥＲ来作为目标函数，而不需要去优
化一个别的目标函数。）
  ＣＴＣ是一种让网络自动学会对齐的好方法，十分适合语音识别和书写识别。
  算法：
  ＣＴＣ算法可以根据输入ｘ映射一些带有概率的Ｙ，而计算概率的关键在于算法如何看待输入和输出之间的一致性。
在讨论它是如何计算损失和进行推理前，我们先来看一下什么叫对齐。
  对齐：
  CTC算法不要求输入和输出的严格对齐，但是为了计算概率大小，总结两者的一些对齐规律的必要的，这之中涉及一
些损失计算。
  一个简单的例子：假设输入Ｘ长度为６，输出Ｙ=[c,a,t]，那么对齐ｘ和ｙ的一种有效方法是为每个输入长度分配
一个输出字符并重复折叠。
这样做会出现两个问题：１、通常情况下，强制要求输入与输出的严格对齐是没有意义的。例如在语音识别中，输入可以有一
些静音，但模型不必给出相应的输出；无法产生连续多个相同字符。如果输入是[h, h, e, l, l, l, o]，CTC会折叠重
复的字符输出“helo”，而不是“hello”。
为了解决这些问题，ＣＴＣ加入了一个空白字符ｂｌａｎｋ，它不对应任何输入，最后会从输出中被删除。
由于ＣＴＣ允许路径长度和输入长度等长，映射到Ｙ的相邻ｂｌａｎｋ可以合并整合，最后统一去除：
[h, h, e, blank，blank，l, l, l,blank，ｌ，ｌ， o]
[h,e,blank,l,blank,l,o]
[h,e, ,l, ,l,o]
[h,e,l,l,o]
