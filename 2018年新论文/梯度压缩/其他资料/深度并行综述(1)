
大规模机器学习（深度学习）并行优化综述
硬件加速：
-CPU + GPU
-CPU + mic处理器
-专用处理器TPU等
常用框架：
-MPI
-CUDA
-OPENCL
-SPARK
数据并行：
-参数服务器
-参数服务器相关优化
--通信
----压缩
----次数
----时机
--结构
----整体架构
----冗余等

模型并行
-计算组件分割
-层为单位分割
-流水线并行
-常用等数据并行算法：分布式逻辑回归，分布式矩阵计算，分布式图计算

分布式梯度下降法优化

成熟的相关软件与应用

各大开源参数服务器性能对比
